{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "articles = {}\n",
    "stat = { }\n",
    "for dirpath, subdirs, files in os.walk('/kaggle/input'):\n",
    "    for x in files:\n",
    "        if x.endswith(\".json\"):\n",
    "            articles[x] = os.path.join(dirpath, x)        \n",
    "df = pd.read_csv('metadata.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Research Status\n",
    "\n",
    "The curent research notebook is focusin on understanding the behavior of the coronavirus by scraping the provided articles. The current version of the notebook is providing information about the following:\n",
    "* Symptoms\n",
    "* Incubation Period\n",
    "* Quarantine\n",
    "* Transmission Methods\n",
    "\n",
    "The mining is running on a custom rule matching engine built on top of Spacy in order to use POS in terms identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare term libraries\n",
    "\n",
    "* virus_ref - virus references in articles. is used to filter the dataset when specific referentiation is needed\n",
    "* symptoms - list of generic symptoms\n",
    "* higher_terms - list of terms that are used to define the starting point of an age group\n",
    "* lower_terms - list of terms that are used to define the end of an age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "virus_ref = ['covid-19', 'coronavirus', 'cov-2', 'sars-cov-2', 'sars-cov', 'hcov', '2019-ncov']\n",
    "symptoms = ['weight loss','chills','shivering','convulsions','deformity','discharge','dizziness','vertigo','fatigue','malaise','asthenia','hypothermia','jaundice','muscle weakness','pyrexia','sweats','swelling','swollen','painful lymph node','weight gain','arrhythmia','bradycardia','chest pain','claudication','palpitations','tachycardia','dry mouth','epistaxis','halitosis','hearing loss','nasal discharge','otalgia','otorrhea','sore throat','toothache','tinnitus','trismus','abdominal pain','fever','bloating','belching','bleeding','blood in stool','melena','hematochezia', 'constipation','diarrhea','dysphagia','dyspepsia','fecal incontinence','flatulence','heartburn','nausea','odynophagia','proctalgia fugax','pyrosis','steatorrhea','vomiting','alopecia','hirsutism','hypertrichosis','abrasion','anasarca','bleeding into the skin','petechia','purpura','ecchymosis and bruising','blister','edema','itching','laceration','rash','urticaria','abnormal posturing','acalculia','agnosia','alexia','amnesia','anomia','anosognosia','aphasia and apraxia','apraxia','ataxia','cataplexy','confusion','dysarthria','dysdiadochokinesia','dysgraphia','hallucination','headache','akinesia','bradykinesia','akathisia','athetosis','ballismus','blepharospasm','chorea','dystonia','fasciculation','muscle cramps','myoclonus','opsoclonus','tic','tremor','flapping tremor','insomnia','loss of consciousness','syncope','neck stiffness','opisthotonus','paralysis and paresis','paresthesia','prosopagnosia','somnolence','abnormal vaginal bleeding','vaginal bleeding in early pregnancy', 'miscarriage','vaginal bleeding in late pregnancy','amenorrhea','infertility','painful intercourse','pelvic pain','vaginal discharge','amaurosis fugax','amaurosis','blurred vision','double vision','exophthalmos','mydriasis','miosis','nystagmus','amusia','anhedonia','anxiety','apathy','confabulation','depression','delusion','euphoria','homicidal ideation','irritability','mania','paranoid ideation','suicidal ideation','apnea','hypopnea','cough','dyspnea','bradypnea','tachypnea','orthopnea','platypnea','trepopnea','hemoptysis','pleuritic chest pain','sputum production','arthralgia','back pain','sciatica','Urologic','dysuria','hematospermia','hematuria','impotence','polyuria','retrograde ejaculation','strangury','urethral discharge','urinary frequency','urinary incontinence','urinary retention']\n",
    "higher_terms = ['over', 'above', 'higher', 'older', '>', 'over', 'less']\n",
    "lower_terms = ['under', 'below', 'fewer', 'younger', '<', 'under', 'more']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defined generic Spacy pattern matchers and util library\n",
    "\n",
    "the patterns will be used in order to assemble a set of rules to identify the desired sequence of patterns\n",
    "\n",
    "* matchers\n",
    " - Term Matcher - lookout for a single term\n",
    " - Terms Matcher - lookout in a list of terms\n",
    " - Number Suffix Matcher - search for numeric value preceeded by a time definition (parametrized, e.g: [\"day\", \"year\"])\n",
    " - Number Interval Matcher - search for numeric intervals of time definition (parametrized, e.g: [\"minute\", \"day\", \"year\"])\n",
    " \n",
    " \n",
    "* plot_dict - utility to plot a dictionary\n",
    "* dict_counter - increase or set the value of a key in the dictionary\n",
    "* day_value - report the time value in days\n",
    "* report_interval - populates dictionary with values for an interval (e.g. 4-7 => {4: 1, 5: 1, 6: 1, 7: 1})\n",
    "* virus_match - checks if any virus term is referenced in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "matchers = {    \n",
    "    \"Term Matcher\": lambda term: [{'LOWER': t} for t in term.split(' ')],\n",
    "    \"Terms Matcher\": lambda terms: [{\"LOWER\": {\"IN\": terms } }],\n",
    "    \"Number Suffix Matcher\": lambda periods: [\n",
    "        {'LIKE_NUM': True},\n",
    "        {\"TEXT\": {\"REGEX\": f'({\"|\".join(periods)})'}}\n",
    "    ],\n",
    "    \"Number Interval Matcher\": lambda periods: [\n",
    "        {'POS': 'NUM',},\n",
    "        {'TEXT': {'REGEX': f'({\"|\".join(periods)})'}, 'OP': '?'},\n",
    "        {'DEP': 'quantmod', 'OP': '?'},\n",
    "        {'DEP': 'punct', 'OP': '?'},\n",
    "        {'DEP': 'prep', 'OP': '?'},\n",
    "        {'POS': 'NUM'},\n",
    "        {'TEXT': {'REGEX': f'({\"|\".join(periods)})'}},\n",
    "    ],\n",
    "    \"Group Matcher\": [\n",
    "        {\"TEXT\": {\"IN\": higher_terms+lower_terms }}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_dict(stat, t = 10, sort_values = False):\n",
    "    filtered = dict(stat)\n",
    "    to_delete = []\n",
    "    for key in filtered:\n",
    "        if filtered[key] < t:\n",
    "            to_delete.append(key)\n",
    "    for key in to_delete:\n",
    "        del filtered[key]\n",
    "\n",
    "    \n",
    "    if sort_values == False:\n",
    "        lists = sorted(filtered.items())\n",
    "    else:\n",
    "        lists = sorted(filtered.items(),key=lambda item: item[1])\n",
    "        \n",
    "    figure(num=None, figsize=(20, 4))\n",
    "    x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "    plt.bar(x, y)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def merge_keys(mergers, obj):\n",
    "    result = dict(obj)\n",
    "    for key, arr in mergers:\n",
    "        if key not in result:\n",
    "            result[key] = 0\n",
    "        for merger in arr:\n",
    "            if merger in result:\n",
    "                result[key] = result[key] + result[merger]\n",
    "                del result[merger]\n",
    "    return result\n",
    "\n",
    "def dict_counter(res, arg):\n",
    "    try:\n",
    "        key = str(arg)\n",
    "        res.setdefault(key, 0)\n",
    "        res[key] = res[key] + 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def numval(val):\n",
    "    try:\n",
    "        return int(float(str(val))) \n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def day_value(val, rep = None):\n",
    "    \n",
    "    if rep != None:\n",
    "        val = numval(val.text)\n",
    "        if val != None and 'week' in rep.text:\n",
    "            val = val * 7\n",
    "        return val\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def report_interval(res, min_val, max_val):       \n",
    "    if min_val != None and max_val != None:\n",
    "        for key in range(min_val, max_val):\n",
    "            res.setdefault(key, 0)\n",
    "            res[key] = res[key] + 1    \n",
    "\n",
    "def virus_match(text):\n",
    "    return len(re.findall(rf'\\ ({\"|\".join(virus_ref)})\\ ', text)) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare COVID-19 Literature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44220/44220 [00:04<00:00, 10183.75it/s]\n"
     ]
    }
   ],
   "source": [
    "literature = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    sha = str(row['sha'])\n",
    "    if sha != 'nan':\n",
    "        sha = sha + '.json';\n",
    "        try:\n",
    "            allow = False\n",
    "            with open(articles[sha]) as f:\n",
    "                data = json.load(f)\n",
    "                for key in ['abstract', 'body_text']:\n",
    "                    if allow == False and key in data:\n",
    "                        for abstract in data['abstract']:\n",
    "                            allow = allow or virus_match(abstract['text'])\n",
    "                            if allow:\n",
    "                                literature.append({'file': articles[sha], 'abstract': data['abstract'], 'body': data['body_text']})\n",
    "                                break;\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define rule matching execution functions\n",
    "\n",
    "When executing a set of rules on a text body the order of the mathcers will be appended to the matching array that will allow the user to define conditional executions when rules match. \n",
    "\n",
    "Rule example:\n",
    "```\n",
    "rule = {    \n",
    "    \"Matchers\": [\n",
    "        (\"Term Matcher\", [\n",
    "            {\"LOWER\": \"incubation\"},\n",
    "            {\"LOWER\": \"period\", \"OP\": \"?\"}\n",
    "        ]),\n",
    "        (\"Time Matcher\", matchers[\"Number Suffix Matcher\"]([\"days\", \"weeks\"])),\n",
    "        (\"Time Interval Matcher\", matchers[\"Number Interval Matcher\"]([\"days\", \"weeks\"]))\n",
    "    ],\n",
    "    \"root\": {          \n",
    "        \"Term Matcher\": { \n",
    "            \"execute\": lambda x: print(x),\n",
    "            \"Time Matcher\": incubation_period_report ,\n",
    "            \"Time Interval Matcher\": incubation_period_report,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "A rule is made of *Matchers* and *executors* - starting with **root executor**. The example above defines the following matchers:\n",
    "* Term Matcher -> looks for the term **incubation** and optionally **period**\n",
    "* Time Matcher -> matches all time references in days / weeks\n",
    "* Time Interval Matcher -> matches all time intervals in days / weeks\n",
    "\n",
    "The next item in the dictionary is *root* that defines the preferred matching order execution (if the order is not satisfied then the matcher executor won't get called)\n",
    "* Term Matcher -> Time Matcher\n",
    "* Term Matcher -> Time Interval Matcher\n",
    "\n",
    "If the matcher rule has the **execute** key present in the dictionary then the rule will get executed even if further specific matchers will get called later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_matches(match_arr, root, sentence, file, aggregate = []):\n",
    "    key, result = match_arr[0]\n",
    "    rest = match_arr[1:]\n",
    "    state = aggregate + [(key, result)]\n",
    "    \n",
    "    if key in root:\n",
    "        rule = root[key]\n",
    "        if callable(rule):\n",
    "            rule( (result, state, sentence, file) )\n",
    "        else:\n",
    "            if 'execute' in rule:\n",
    "                rule['execute']( (result, state, sentence, file) )\n",
    "            if len(rest) > 0:\n",
    "                execute_matches(rest, rule, sentence, file, state)\n",
    "    \n",
    "    if len(rest) > 0:\n",
    "        execute_matches(rest, root, sentence, file, state)\n",
    "\n",
    "def match_parser(matcher, doc, rule, file):\n",
    "    matches = matcher(doc)\n",
    "    if len(matches)>0:\n",
    "        to_process = []\n",
    "        for match_id, start, end in matches:\n",
    "            string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "            span = doc[start:end]  # The matched span\n",
    "            to_process.append((string_id, span))\n",
    "        execute_matches(to_process, rule['root'], doc, file)\n",
    "\n",
    "def parse_body(matcher, text, rule, file = None, sentence_level = False):\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    if sentence_level == True:    \n",
    "        for sent in doc.sents:\n",
    "            sent_doc = nlp(sent.text)\n",
    "            match_parser(matcher, sent_doc, rule, file)\n",
    "    else:\n",
    "        match_parser(matcher, doc, rule, file)\n",
    "\n",
    "def execute_ruleset(term, rule, sentence_level = False):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    for name, m in rule[\"Matchers\"]:\n",
    "        matcher.add(name, None, m)\n",
    "    \n",
    "    for article in tqdm(literature):\n",
    "        abstracts = article['abstract']\n",
    "        body = article['body']\n",
    "        file = article['file']\n",
    "        \n",
    "        for body_text in body:\n",
    "            text = body_text['text']\n",
    "            if callable(term):\n",
    "                allow = term(text)\n",
    "            else:\n",
    "                allow = term == None or term in text\n",
    "            if allow == True:\n",
    "                parse_body(matcher, text, rule, file, sentence_level)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virus Symptoms\n",
    "\n",
    "Search for virus references and its symptoms in all articles that have a coronavirus reference and at least one term in symptoms dictionary\n",
    "Since is really important to understand the symptoms the search will be performed on the entire article dataset with no filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'symptoms': {}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1de2f2cc7168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mexecute_ruleset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymptom_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mplot_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symptoms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-58ff1ab47723>\u001b[0m in \u001b[0;36mplot_dict\u001b[0;34m(stat, t, sort_values)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unpack a list of pairs into two tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stat['symptoms'] = {}\n",
    "\n",
    "def match(text):\n",
    "    if virus_match(text) == True:\n",
    "        return len(re.findall(rf'\\ ({\"|\".join(symptoms)})\\ ', text)) > 0\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def symptom(res):\n",
    "    ref, agregate, sentence, file = res\n",
    "    dict_counter(stat['symptoms'], ref.text)\n",
    "        \n",
    "rule = {    \n",
    "    \"Matchers\": [      \n",
    "       (\"Symptoms Reference\", matchers['Terms Matcher'](symptoms)),\n",
    "    ],\n",
    "    \"root\": {\n",
    "        \"Symptoms Reference\": symptom\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def symptom_match(text):\n",
    "    return len(re.findall(r'symptom', text)) > 0\n",
    "\n",
    "execute_ruleset(symptom_match, rule)\n",
    "plot_dict(stat['symptoms'], 50, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incubation Period\n",
    "\n",
    "The first analysis is parsing filtered articles that might refer to COVID-19 incubation period. For the moment the term *incubation period* is searched in text abstract in order to identify the potential articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-46cbb353c4f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mexecute_ruleset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'incubation period'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mplot_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'incubation_periods'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-58ff1ab47723>\u001b[0m in \u001b[0;36mplot_dict\u001b[0;34m(stat, t, sort_values)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unpack a list of pairs into two tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stat['incubation_periods'] = {}\n",
    "\n",
    "def incubation_period_report(x):\n",
    "    arr = x[1][-2:]\n",
    "    m1, v1 = arr[0]\n",
    "    m2, v2 = arr[1]\n",
    "    \n",
    "    if m1 == 'Term Matcher':\n",
    "        if m2 == 'Time Matcher':\n",
    "            report_interval(stat['incubation_periods'], 0, day_value(v2[0], v2[1]))            \n",
    "        elif m2 == 'Time Interval Matcher':\n",
    "            report_interval(stat['incubation_periods'], day_value(v2[0], v2[3]), day_value(v2[1], v2[1]))           \n",
    "    elif m2 == 'Term Matcher':\n",
    "        if m2 == 'Time Matcher':\n",
    "            report_interval(stat['incubation_periods'], 0, day_value(v2[0], v2[1]))\n",
    "        elif m2 == 'Time Interval Matcher':\n",
    "            report_interval(stat['incubation_periods'], day_value(v2[0], v2[3]), day_value(v2[1], v2[1]))      \n",
    "\n",
    "rule = {    \n",
    "    \"Matchers\": [\n",
    "        (\"Term Matcher\", [\n",
    "            {\"LOWER\": \"incubation\"},\n",
    "            {\"LOWER\": \"period\", \"OP\": \"?\"}\n",
    "        ]),\n",
    "        (\"Time Matcher\", matchers[\"Number Suffix Matcher\"]([\"days\", \"weeks\"])),\n",
    "        (\"Time Interval Matcher\", matchers[\"Number Interval Matcher\"]([\"days\", \"weeks\"]))\n",
    "    ],\n",
    "    \"root\": {          \n",
    "        \"Term Matcher\": { \n",
    "            \"Time Matcher\": incubation_period_report ,\n",
    "            \"Time Interval Matcher\": incubation_period_report,\n",
    "        },\n",
    "        \"Day Matcher\": { \"Term Matcher\": incubation_period_report },\n",
    "        \"Day Interval Matcher\": { \"Term Matcher\": incubation_period_report }\n",
    "    }\n",
    "}\n",
    "\n",
    "execute_ruleset('incubation period', rule)\n",
    "plot_dict(stat['incubation_periods'], 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quarantine\n",
    "\n",
    "Searches for all quarantine recommendations in the articles where coronavirus term is present. The lookout will be performed at the sentence level and not at the full body level for a better approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2d566fa33993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mexecute_ruleset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quarantine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mplot_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quarantine'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-58ff1ab47723>\u001b[0m in \u001b[0;36mplot_dict\u001b[0;34m(stat, t, sort_values)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unpack a list of pairs into two tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stat['quarantine'] = {}\n",
    "\n",
    "def quarantine_matcher(text):\n",
    "    return virus_match(text) == True and 'quarantine' in text\n",
    "\n",
    "def quarantine_report(x):\n",
    "    arr = x[1][-2:]\n",
    "    m1, v1 = arr[0]\n",
    "    m2, v2 = arr[1]\n",
    "    \n",
    "    if m1 == 'Quarantine Matcher':\n",
    "        if m2 == 'Time Matcher':\n",
    "            report_interval(stat['quarantine'], 0, day_value(v2[0], v2[1]))            \n",
    "        elif m2 == 'Time Interval Matcher':\n",
    "            report_interval(stat['quarantine'], day_value(v2[0], v2[3]), day_value(v2[1], v2[1]))           \n",
    "    elif m2 == 'Quarantine Matcher':\n",
    "        if m2 == 'Time Matcher':\n",
    "            report_interval(stat['quarantine'], 0, day_value(v2[0], v2[1]))\n",
    "        elif m2 == 'Time Interval Matcher':\n",
    "            report_interval(stat['quarantine'], day_value(v2[0], v2[3]), day_value(v2[1], v2[1]))      \n",
    "            \n",
    "rule = {    \n",
    "    \"Matchers\": [\n",
    "        (\"Quarantine Matcher\", [\n",
    "            {\"LOWER\": \"quarantine\"},\n",
    "        ]),\n",
    "        \n",
    "        (\"Time Matcher\", matchers[\"Number Suffix Matcher\"]([\"days\", \"weeks\"])),\n",
    "        (\"Time Interval Matcher\", matchers[\"Number Interval Matcher\"]([\"days\", \"weeks\"]))\n",
    "    ],\n",
    "    \"root\": {          \n",
    "        \"Quarantine Matcher\": { \n",
    "            \"Time Matcher\": quarantine_report ,\n",
    "            \"Time Interval Matcher\": quarantine_report,\n",
    "        },\n",
    "        \"Day Matcher\": { \"Quarantine Matcher\": quarantine_report },\n",
    "        \"Day Interval Matcher\": { \"Quarantine Matcher\": quarantine_report }\n",
    "    }\n",
    "}\n",
    "\n",
    "execute_ruleset('quarantine', rule)\n",
    "plot_dict(stat['quarantine'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transmission methods\n",
    "\n",
    "Searches for all transmission method (NOUNS) in articles where coronavirus is mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-39f528846ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mplot_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-58ff1ab47723>\u001b[0m in \u001b[0;36mplot_dict\u001b[0;34m(stat, t, sort_values)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unpack a list of pairs into two tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stat['transmission'] = {}\n",
    "def process_matcher(x):\n",
    "    arr = x[1][-4:]\n",
    "    sentence = x[2]\n",
    "    m1, v1 = arr[0]\n",
    "    m2, v2 = arr[1]\n",
    "    m3, v3 = arr[2]\n",
    "    m4, v4 = arr[3]\n",
    "    if m1 == 'Term Matcher' and m2 == \"Verbs Matcher\" and m3 == \"Form Matcher\":\n",
    "#         print(v1, '->', v4, sentence[v3.end:v4.end], '>>>', sentence[v3.end:])\n",
    "        tokens = []\n",
    "        for token in sentence[v3.end:]:\n",
    "            if token.pos_ == 'PUNCT' and token.tag_ != 'HYPH':\n",
    "                break;\n",
    "            else:\n",
    "                tokens.append(token.lemma_)\n",
    "        result = ' '.join(tokens)\n",
    "        result = re.sub(r' - ', '-', result)\n",
    "        \n",
    "        for res in re.split(r' (and|or) ', result):\n",
    "            val = res.strip()\n",
    "            if len(val) > 1 and val not in ['or', 'and']:\n",
    "                dict_counter(stat['transmission'], val)\n",
    "        \n",
    "        \n",
    "rule = {    \n",
    "    \"Matchers\": [\n",
    "        (\"Term Matcher\", matchers[\"Terms Matcher\"](['transmit','transmitted', 'spread', 'spreaded'])),\n",
    "        (\"Form Matcher\", matchers[\"Terms Matcher\"](['through', 'by', 'via'])),\n",
    "        (\"Verbs Matcher\", [            \n",
    "            {\"POS\": \"VERB\"},            \n",
    "        ]),\n",
    "        (\"Noun Matcher\", [\n",
    "            {\"POS\": \"NOUN\"},            \n",
    "        ])\n",
    "    ],\n",
    "    \"root\": {          \n",
    "        \"Term Matcher\": {\n",
    "            \"Form Matcher\": {\n",
    "                \"Noun Matcher\": process_matcher\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def filter(text):\n",
    "    return len(re.findall(r'(transmitted|transmit|spread|spreaded)', text)) > 0\n",
    "\n",
    "execute_ruleset(filter, rule, sentence_level = False)\n",
    "\n",
    "filtered = dict(stat['transmission'])\n",
    "\n",
    "to_delete = []\n",
    "for key in filtered:\n",
    "    if filtered[key] < 5 or len(key) > 20:\n",
    "        to_delete.append(key)\n",
    "for key in to_delete:\n",
    "    del filtered[key]\n",
    "\n",
    "plot_dict(filtered, 6, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
